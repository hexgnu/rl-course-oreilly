{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we beat our original Q-Learner trader?\n",
    "\n",
    "So we have shown that over a _specific_ time slice of the S&P 500 we can beat the market. Although that period of time was more about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from util import create_df_benchmark, get_data\n",
    "from marketsim import compute_portvals_single_symbol, market_simulator\n",
    "from strategy import StrategyLearner\n",
    "from analysis import get_portfolio_value, get_portfolio_stats\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_TO_POSITION = {0: -1, 1: 0, 2: 1}\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(60, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(60, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(3) - 1 # Full bore buy or sell or hold\n",
    "            # return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(np.asarray([state]))\n",
    "        return np.max(act_values[0])  # returns action\n",
    "    \n",
    "    def _state_target(self, memory):\n",
    "        states = []\n",
    "        target_fs = []\n",
    "        for state, action, reward, next_state, done in memory:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * \\\n",
    "                         np.amax(self.model.predict(np.asarray([next_state]))[0])\n",
    "            target_f = self.model.predict(np.asarray([state]))\n",
    "            # target_f[0][action] = target\n",
    "            target_f[0] = action * target\n",
    "            states.append(state)\n",
    "            target_fs.append(target_f)\n",
    "        \n",
    "        return (states, target_fs)\n",
    "    \n",
    "    def replay(self, validation_df=None):\n",
    "        validation_memory = self.create_memory(validation_df, validation_df.index[-1], memory=[])\n",
    "        \n",
    "        v_states, v_target_fs = self._state_target(validation_memory)\n",
    "        states, target_fs = self._state_target(self.memory)\n",
    "        self.model.fit(np.asarray(states), np.asarray(target_fs)[:, 0, :], \\\n",
    "                       validation_data=(np.asarray(v_states),  np.asarray(v_target_fs)[:, 0, :]),\n",
    "                       epochs=10, verbose=1)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "    \n",
    "    def create_memory(self, df, end_date, memory=[]):\n",
    "        for i, (d, r) in enumerate(df.iloc[self.state_size:-2].iterrows()):\n",
    "            state = np.asarray(df.iloc[i:i+self.state_size]['SPY_ret'])\n",
    "            action = self.act(state)\n",
    "            next_state = np.asarray(df.iloc[i+1:i+self.state_size+1]['SPY_ret'])\n",
    "            done = d == end_date\n",
    "            reward = action * df.iloc[i+self.state_size+1]['SPY_ret']    \n",
    "            memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_date = dt.datetime(2007, 1, 1)\n",
    "train_end_date   = dt.datetime(2007, 12, 31)\n",
    "portfolio_start_date = dt.datetime(2008, 1, 1)\n",
    "portfolio_end_date = dt.datetime(2008, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hexgnu/.pyenv/versions/3.7.3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  after removing the cwd from sys.path.\n",
      "/home/hexgnu/.pyenv/versions/3.7.3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.3968 - val_loss: 0.3284\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 137us/step - loss: 0.3743 - val_loss: 0.3047\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 229us/step - loss: 0.3436 - val_loss: 0.2752\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 187us/step - loss: 0.3073 - val_loss: 0.2416\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 272us/step - loss: 0.2654 - val_loss: 0.2082\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 299us/step - loss: 0.2257 - val_loss: 0.1799\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 252us/step - loss: 0.1945 - val_loss: 0.1613\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 251us/step - loss: 0.1709 - val_loss: 0.1523\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 206us/step - loss: 0.1604 - val_loss: 0.1485\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 205us/step - loss: 0.1547 - val_loss: 0.1472\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 144us/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 179us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 231us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 245us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 175us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 194us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 257us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 205us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 195us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 160us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 105us/step - loss: 8.6746e-04 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 129us/step - loss: 8.1605e-04 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 112us/step - loss: 7.7340e-04 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 159us/step - loss: 7.3790e-04 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 180us/step - loss: 7.0827e-04 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 159us/step - loss: 6.7927e-04 - val_loss: 9.9141e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 205us/step - loss: 6.5499e-04 - val_loss: 9.6697e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 154us/step - loss: 6.3265e-04 - val_loss: 9.4563e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 199us/step - loss: 6.1462e-04 - val_loss: 9.2533e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 213us/step - loss: 5.9641e-04 - val_loss: 9.0791e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 87us/step - loss: 4.1943e-04 - val_loss: 7.7663e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 132us/step - loss: 4.0416e-04 - val_loss: 7.6177e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 187us/step - loss: 3.9058e-04 - val_loss: 7.4806e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 181us/step - loss: 3.7740e-04 - val_loss: 7.3571e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 200us/step - loss: 3.6608e-04 - val_loss: 7.2405e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 139us/step - loss: 3.5506e-04 - val_loss: 7.1385e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 179us/step - loss: 3.4513e-04 - val_loss: 7.0487e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 138us/step - loss: 3.3684e-04 - val_loss: 6.9632e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 152us/step - loss: 3.2901e-04 - val_loss: 6.8855e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 174us/step - loss: 3.2198e-04 - val_loss: 6.8128e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 85us/step - loss: 2.2154e-04 - val_loss: 6.1448e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 162us/step - loss: 2.1434e-04 - val_loss: 6.0689e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 119us/step - loss: 2.0799e-04 - val_loss: 5.9953e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 196us/step - loss: 2.0202e-04 - val_loss: 5.9261e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 206us/step - loss: 1.9628e-04 - val_loss: 5.8628e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 140us/step - loss: 1.9109e-04 - val_loss: 5.8060e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 163us/step - loss: 1.8647e-04 - val_loss: 5.7525e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 148us/step - loss: 1.8207e-04 - val_loss: 5.7043e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 162us/step - loss: 1.7817e-04 - val_loss: 5.6605e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 204us/step - loss: 1.7448e-04 - val_loss: 5.6202e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 100us/step - loss: 1.3157e-04 - val_loss: 6.1114e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 151us/step - loss: 1.2862e-04 - val_loss: 6.0765e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 160us/step - loss: 1.2616e-04 - val_loss: 6.0431e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 224us/step - loss: 1.2374e-04 - val_loss: 6.0128e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 230us/step - loss: 1.2153e-04 - val_loss: 5.9845e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 261us/step - loss: 1.1948e-04 - val_loss: 5.9583e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 249us/step - loss: 1.1754e-04 - val_loss: 5.9343e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 188us/step - loss: 1.1581e-04 - val_loss: 5.9110e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 177us/step - loss: 1.1414e-04 - val_loss: 5.8886e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 142us/step - loss: 1.1258e-04 - val_loss: 5.8678e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 118us/step - loss: 1.2627e-04 - val_loss: 5.5825e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 178us/step - loss: 1.2500e-04 - val_loss: 5.5659e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 163us/step - loss: 1.2386e-04 - val_loss: 5.5498e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 177us/step - loss: 1.2271e-04 - val_loss: 5.5355e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 119us/step - loss: 1.2166e-04 - val_loss: 5.5224e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 144us/step - loss: 1.2075e-04 - val_loss: 5.5096e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 172us/step - loss: 1.1986e-04 - val_loss: 5.4971e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 234us/step - loss: 1.1900e-04 - val_loss: 5.4848e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 140us/step - loss: 1.1817e-04 - val_loss: 5.4733e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 191us/step - loss: 1.1737e-04 - val_loss: 5.4626e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 94us/step - loss: 1.0048e-04 - val_loss: 6.3733e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 207us/step - loss: 9.9725e-05 - val_loss: 6.3606e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 166us/step - loss: 9.8886e-05 - val_loss: 6.3486e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 144us/step - loss: 9.8104e-05 - val_loss: 6.3376e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 171us/step - loss: 9.7401e-05 - val_loss: 6.3269e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 239us/step - loss: 9.6670e-05 - val_loss: 6.3171e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 247us/step - loss: 9.6064e-05 - val_loss: 6.3067e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 172us/step - loss: 9.5416e-05 - val_loss: 6.2972e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 160us/step - loss: 9.4795e-05 - val_loss: 6.2886e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 170us/step - loss: 9.4245e-05 - val_loss: 6.2799e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 76us/step - loss: 1.0862e-04 - val_loss: 3.6479e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 124us/step - loss: 1.0821e-04 - val_loss: 3.6418e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 110us/step - loss: 1.0780e-04 - val_loss: 3.6361e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 208us/step - loss: 1.0740e-04 - val_loss: 3.6310e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 171us/step - loss: 1.0706e-04 - val_loss: 3.6256e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 159us/step - loss: 1.0671e-04 - val_loss: 3.6208e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 182us/step - loss: 1.0640e-04 - val_loss: 3.6160e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 187us/step - loss: 1.0608e-04 - val_loss: 3.6116e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 170us/step - loss: 1.0578e-04 - val_loss: 3.6074e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 181us/step - loss: 1.0551e-04 - val_loss: 3.6033e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 97us/step - loss: 9.6352e-05 - val_loss: 4.1536e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 183us/step - loss: 9.6004e-05 - val_loss: 4.1487e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 162us/step - loss: 9.5607e-05 - val_loss: 4.1438e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 198us/step - loss: 9.5239e-05 - val_loss: 4.1391e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 176us/step - loss: 9.4836e-05 - val_loss: 4.1347e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 175us/step - loss: 9.4505e-05 - val_loss: 4.1300e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 210us/step - loss: 9.4131e-05 - val_loss: 4.1258e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 142us/step - loss: 9.3813e-05 - val_loss: 4.1219e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 164us/step - loss: 9.3508e-05 - val_loss: 4.1181e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 158us/step - loss: 9.3210e-05 - val_loss: 4.1144e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 90us/step - loss: 9.9867e-05 - val_loss: 5.3685e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 118us/step - loss: 9.9545e-05 - val_loss: 5.3654e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 163us/step - loss: 9.9222e-05 - val_loss: 5.3626e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 162us/step - loss: 9.8951e-05 - val_loss: 5.3596e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 141us/step - loss: 9.8605e-05 - val_loss: 5.3570e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 156us/step - loss: 9.8342e-05 - val_loss: 5.3543e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 167us/step - loss: 9.8064e-05 - val_loss: 5.3518e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 215us/step - loss: 9.7792e-05 - val_loss: 5.3495e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 193us/step - loss: 9.7550e-05 - val_loss: 5.3472e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 156us/step - loss: 9.7308e-05 - val_loss: 5.3450e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 89us/step - loss: 6.4131e-05 - val_loss: 3.4944e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 177us/step - loss: 6.3961e-05 - val_loss: 3.4922e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 172us/step - loss: 6.3823e-05 - val_loss: 3.4901e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 165us/step - loss: 6.3680e-05 - val_loss: 3.4882e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 160us/step - loss: 6.3546e-05 - val_loss: 3.4864e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 188us/step - loss: 6.3424e-05 - val_loss: 3.4845e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 189us/step - loss: 6.3297e-05 - val_loss: 3.4827e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 185us/step - loss: 6.3186e-05 - val_loss: 3.4810e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 189us/step - loss: 6.3078e-05 - val_loss: 3.4793e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 158us/step - loss: 6.2954e-05 - val_loss: 3.4778e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 66us/step - loss: 6.8386e-05 - val_loss: 5.7036e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 143us/step - loss: 6.8308e-05 - val_loss: 5.7022e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 238us/step - loss: 6.8239e-05 - val_loss: 5.7008e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 197us/step - loss: 6.8169e-05 - val_loss: 5.6997e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 165us/step - loss: 6.8110e-05 - val_loss: 5.6984e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 185us/step - loss: 6.8054e-05 - val_loss: 5.6972e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 154us/step - loss: 6.7993e-05 - val_loss: 5.6960e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 188us/step - loss: 6.7930e-05 - val_loss: 5.6950e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 197us/step - loss: 6.7877e-05 - val_loss: 5.6939e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 166us/step - loss: 6.7819e-05 - val_loss: 5.6928e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 123us/step - loss: 7.1260e-05 - val_loss: 5.1596e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 174us/step - loss: 7.1173e-05 - val_loss: 5.1585e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 164us/step - loss: 7.1079e-05 - val_loss: 5.1575e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 155us/step - loss: 7.0966e-05 - val_loss: 5.1567e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 164us/step - loss: 7.0880e-05 - val_loss: 5.1558e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 199us/step - loss: 7.0778e-05 - val_loss: 5.1550e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 149us/step - loss: 7.0696e-05 - val_loss: 5.1541e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 217us/step - loss: 7.0612e-05 - val_loss: 5.1533e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 213us/step - loss: 7.0523e-05 - val_loss: 5.1525e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 153us/step - loss: 7.0452e-05 - val_loss: 5.1517e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 66us/step - loss: 8.1188e-05 - val_loss: 4.3855e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 150us/step - loss: 8.1128e-05 - val_loss: 4.3841e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 150us/step - loss: 8.1069e-05 - val_loss: 4.3827e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 144us/step - loss: 8.1003e-05 - val_loss: 4.3816e-04\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 0s 161us/step - loss: 8.0947e-05 - val_loss: 4.3803e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 163us/step - loss: 8.0891e-05 - val_loss: 4.3792e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 189us/step - loss: 8.0836e-05 - val_loss: 4.3781e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 215us/step - loss: 8.0788e-05 - val_loss: 4.3769e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 190us/step - loss: 8.0735e-05 - val_loss: 4.3758e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 130us/step - loss: 8.0681e-05 - val_loss: 4.3747e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 116us/step - loss: 7.3314e-05 - val_loss: 5.7974e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 158us/step - loss: 7.3250e-05 - val_loss: 5.7963e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 127us/step - loss: 7.3188e-05 - val_loss: 5.7952e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 202us/step - loss: 7.3125e-05 - val_loss: 5.7941e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 218us/step - loss: 7.3049e-05 - val_loss: 5.7932e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 185us/step - loss: 7.2991e-05 - val_loss: 5.7923e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 221us/step - loss: 7.2933e-05 - val_loss: 5.7913e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 142us/step - loss: 7.2877e-05 - val_loss: 5.7904e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 139us/step - loss: 7.2815e-05 - val_loss: 5.7896e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 161us/step - loss: 7.2770e-05 - val_loss: 5.7886e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 78us/step - loss: 6.0434e-05 - val_loss: 4.5060e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 101us/step - loss: 6.0387e-05 - val_loss: 4.5056e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 208us/step - loss: 6.0348e-05 - val_loss: 4.5053e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 200us/step - loss: 6.0313e-05 - val_loss: 4.5049e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 204us/step - loss: 6.0278e-05 - val_loss: 4.5045e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 241us/step - loss: 6.0239e-05 - val_loss: 4.5042e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 175us/step - loss: 6.0205e-05 - val_loss: 4.5038e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 150us/step - loss: 6.0165e-05 - val_loss: 4.5034e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 168us/step - loss: 6.0128e-05 - val_loss: 4.5031e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 225us/step - loss: 6.0098e-05 - val_loss: 4.5027e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 108us/step - loss: 6.9379e-05 - val_loss: 3.0284e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 133us/step - loss: 6.9356e-05 - val_loss: 3.0283e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 189us/step - loss: 6.9336e-05 - val_loss: 3.0283e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 210us/step - loss: 6.9313e-05 - val_loss: 3.0282e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 170us/step - loss: 6.9298e-05 - val_loss: 3.0282e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 142us/step - loss: 6.9283e-05 - val_loss: 3.0281e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 162us/step - loss: 6.9257e-05 - val_loss: 3.0281e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 163us/step - loss: 6.9246e-05 - val_loss: 3.0280e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 131us/step - loss: 6.9225e-05 - val_loss: 3.0280e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 191us/step - loss: 6.9204e-05 - val_loss: 3.0279e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 85us/step - loss: 5.5217e-05 - val_loss: 4.4509e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 164us/step - loss: 5.5185e-05 - val_loss: 4.4504e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 162us/step - loss: 5.5144e-05 - val_loss: 4.4500e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 162us/step - loss: 5.5106e-05 - val_loss: 4.4494e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 145us/step - loss: 5.5072e-05 - val_loss: 4.4489e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 196us/step - loss: 5.5036e-05 - val_loss: 4.4485e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 132us/step - loss: 5.4996e-05 - val_loss: 4.4480e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 174us/step - loss: 5.4963e-05 - val_loss: 4.4475e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 188us/step - loss: 5.4929e-05 - val_loss: 4.4471e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 180us/step - loss: 5.4895e-05 - val_loss: 4.4466e-04\n",
      "Train on 238 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 0s 176us/step - loss: 6.0962e-05 - val_loss: 4.8847e-04\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 0s 140us/step - loss: 6.0926e-05 - val_loss: 4.8845e-04\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 0s 206us/step - loss: 6.0899e-05 - val_loss: 4.8842e-04\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 0s 161us/step - loss: 6.0867e-05 - val_loss: 4.8840e-04\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 0s 152us/step - loss: 6.0843e-05 - val_loss: 4.8838e-04\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 0s 167us/step - loss: 6.0816e-05 - val_loss: 4.8836e-04\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 0s 241us/step - loss: 6.0789e-05 - val_loss: 4.8834e-04\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 0s 173us/step - loss: 6.0768e-05 - val_loss: 4.8832e-04\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 0s 155us/step - loss: 6.0743e-05 - val_loss: 4.8830e-04\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 0s 159us/step - loss: 6.0713e-05 - val_loss: 4.8828e-04\n"
     ]
    }
   ],
   "source": [
    "window_size = 10\n",
    "\n",
    "training_df = get_data(['SPY'], pd.date_range(train_start_date, train_end_date), addSPY=False)\n",
    "training_df['SPY_ret'] = training_df['SPY'].rolling(window=2).apply(lambda x: x[1] / x[0] - 1)\n",
    "training_df = training_df.dropna()\n",
    "\n",
    "validation_df = get_data(['SPY'], pd.date_range(portfolio_start_date, portfolio_end_date), addSPY=False)\n",
    "validation_df['SPY_ret'] = validation_df['SPY'].rolling(window=2).apply(lambda x: x[1] / x[0] - 1)\n",
    "validation_df = validation_df.dropna()\n",
    "\n",
    "learner = DQNAgent(state_size=window_size, action_size=3)\n",
    "\n",
    "for e in range(20):\n",
    "    learner.memory = []\n",
    "    learner.create_memory(training_df, train_end_date, memory=learner.memory)\n",
    "    learner.replay(validation_df=validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df\n",
    "\n",
    "trades_df = {'trade': []}\n",
    "cum_return = 1\n",
    "\n",
    "for i, (d, r) in enumerate(validation_df.iloc[learner.state_size:-2].iterrows()):\n",
    "        state = np.asarray(validation_df.iloc[i:i+learner.state_size]['SPY_ret'])\n",
    "        position = learner.act(state) # ACTION_TO_POSITION[learner.act(state)]\n",
    "        reward = position * validation_df.iloc[i+learner.state_size]['SPY_ret']\n",
    "        trades_df['trade'].append(position)\n",
    "        cum_return *= 1+reward\n",
    "\n",
    "df_trades = pd.DataFrame(trades_df, index=validation_df.index[learner.state_size+1:-1]).join(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff9a7ee9358>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_trades['portfolio_ret'] = (df_trades['trade'] * df_trades['SPY_ret'])\n",
    "df_trades['portfolio_value'] = (1 + df_trades['portfolio_ret']).cumprod()\n",
    "df_trades['SPY'] = df_trades['SPY'] / df_trades.iloc[0]['SPY']\n",
    "\n",
    "df_trades[['SPY', 'portfolio_value']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performances during testing period for SPY\n",
      "Date Range: 2008-01-03 00:00:00 to 2008-12-31 00:00:00\n",
      "\n",
      "Sharpe Ratio of Portfolio: 0.9664082789960003\n",
      "Sharpe Ratio of Benchmark: -0.8124472725772371\n",
      "\n",
      "Cumulative return of portfolio: 0.2859339613113452\n",
      "Cumulative return of benchmark: -0.3171693926193807\n",
      "\n",
      "Standard Deviation of Portfolio: 0.01795035533393809\n",
      "Standard Deviation of Benchmark: 0.026521696916875993\n",
      "\n",
      "Average Daily Return of Portfolio: 0.0012100854335354335\n",
      "Average Daily Return of Benchmark: -0.0012400599604033109\n",
      "\n",
      "Final Portfolio Value: 128593.39613113452\n",
      "Final Benchmark Value: 68283.06073806193\n"
     ]
    }
   ],
   "source": [
    "print (\"\\nPerformances during testing period for {}\".format(symbol))\n",
    "print (\"Date Range: {} to {}\\n\".format(validation_df.iloc[0].name, validation_df.iloc[-1].name))\n",
    "\n",
    "from util import compute_sharpe_ratio\n",
    "def get_sharpe(series):\n",
    "\n",
    "    rfr = (1.03**(1/252.0))-1\n",
    "\n",
    "    adr = series.mean()\n",
    "    sddr = series.std()\n",
    "    return compute_sharpe_ratio(np.sqrt(252), adr, rfr, sddr)\n",
    "\n",
    "print(\"Sharpe Ratio of Portfolio: {}\".format(get_sharpe(df_trades['portfolio_ret'])))\n",
    "print(\"Sharpe Ratio of Benchmark: {}\\n\".format(get_sharpe(df_trades['SPY_ret'])))\n",
    "\n",
    "print(\"Cumulative return of portfolio: {}\".format((1+df_trades['portfolio_ret']).prod() - 1))\n",
    "print(\"Cumulative return of benchmark: {}\\n\".format((1+df_trades['SPY_ret']).prod() - 1))\n",
    "\n",
    "print(\"Standard Deviation of Portfolio: {}\".format(df_trades['portfolio_ret'].std()))\n",
    "print(\"Standard Deviation of Benchmark: {}\\n\".format(df_trades['SPY_ret'].std()))\n",
    "\n",
    "print(\"Average Daily Return of Portfolio: {}\".format(df_trades['portfolio_ret'].mean()))\n",
    "print(\"Average Daily Return of Benchmark: {}\\n\".format(df_trades['SPY_ret'].mean()))\n",
    "\n",
    "print(\"Final Portfolio Value: {}\".format(100_000 * df_trades.iloc[-1]['portfolio_value']))\n",
    "print(\"Final Benchmark Value: {}\".format(100_000 * (1+df_trades['SPY_ret']).cumprod().iloc[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
